{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "gznim23uja1Z",
   "metadata": {
    "id": "gznim23uja1Z"
   },
   "source": [
    "# üìö Notebook 6.1: Fine-Tune GPT-2 for Text Classification\n",
    "\n",
    "Welcome back to the series! üéâ Now that we‚Äôve explored advanced training techniques in *Notebook 5.2*, it's time to take our GPT-2 model a step further by fine-tuning it for a specific, practical application: **text classification**.\n",
    "\n",
    "### What's the Goal? üèÜ\n",
    "\n",
    "In this notebook, we will adapt the GPT-2 model to classify text data‚Äîa departure from its primary generative capabilities. Fine-tuning a language model like GPT-2 for classification opens up applications in areas such as **spam detection, sentiment analysis, and topic categorization**. This hands-on approach provides insight into how transformer-based models can be repurposed for a wide range of NLP tasks.\n",
    "\n",
    "### What's Inside? üîç\n",
    "\n",
    "This notebook is structured to bridge the gap between **general language modeling** and **task-specific fine-tuning**. Here‚Äôs what we‚Äôll cover:\n",
    "\n",
    "#### **Section 1: Data Preparation for Classification** üìä\n",
    "In this section, we'll focus on:\n",
    "- Structuring our dataset for text classification tasks\n",
    "- Tokenizing and batching the data to optimize training\n",
    "\n",
    "#### **Section 2: Fine-Tuning GPT-2** üîÑ\n",
    "Building on the advanced training methods from *Notebook 5.2*, we‚Äôll apply techniques such as:\n",
    "- Layer freezing and selective unfreezing to control the depth of fine-tuning\n",
    "- Adapting the optimizer and scheduler configurations for stability and performance\n",
    "\n",
    "#### **Section 3: Evaluation and Analysis** üìà\n",
    "After training, we‚Äôll assess our model‚Äôs performance through:\n",
    "- Accuracy, precision, recall, and F1-score evaluations\n",
    "- Visualization of the model‚Äôs classification behavior and confusion matrix\n",
    "\n",
    "\n",
    "\n",
    "Let‚Äôs get started and explore how to make GPT-2 shine as a text classifier! üåü\n",
    "\n",
    "# Introduction to Fine-Tuning\n",
    "\n",
    "Fine-tuning is a crucial process in machine learning that involves adapting a pre-trained model, which has already learned from a large dataset, to a specific task or dataset. Instead of starting from scratch, fine-tuning utilizes the patterns and representations learned during initial training, enabling the model to quickly learn task-specific features with less data.\n",
    "\n",
    "## Key Aspects of Fine-Tuning:\n",
    "\n",
    "- **Efficiency**: Fine-tuning requires fewer resources and time compared to training a new model from the ground up.\n",
    "- **Transfer Learning**: The model retains the broader knowledge gained during pre-training, which enhances its performance on specific tasks.\n",
    "- **Application in NLP**: In natural language processing (NLP), models like GPT-2 are often fine-tuned for tasks such as text classification, sentiment analysis, or summarization.\n",
    "\n",
    "By leveraging a solid foundation of linguistic and contextual understanding, fine-tuning enables models to achieve high performance on specialized tasks while minimizing the data and computational power required.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/finetine.png\" alt=\"My Image\" />\n",
    "</p>\n",
    "\n",
    "## LETS GET STARTED üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
   "metadata": {
    "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90"
   },
   "outputs": [],
   "source": [
    "# Importing the version function from the importlib.metadata module\n",
    "from importlib.metadata import version\n",
    "\n",
    "# List of essential packages for the project\n",
    "pkgs = [\n",
    "    \"matplotlib\",  # For creating static, animated, and interactive visualizations in Python\n",
    "    \"numpy\",       # A fundamental package for scientific computing with support for large, multi-dimensional arrays and matrices\n",
    "    \"tiktoken\",    # Tokenization library used for preparing text data for models like GPT-2\n",
    "    \"torch\",       # PyTorch library for building and training neural networks\n",
    "    \"tensorflow\",  # For loading OpenAI's pretrained weights and performing other tasks\n",
    "    \"pandas\"       # Data manipulation and analysis library, useful for loading and handling datasets\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c",
   "metadata": {
    "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c"
   },
   "source": [
    "## Different categories of finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac45579d-d485-47dc-829e-43be7f4db57b",
   "metadata": {
    "id": "ac45579d-d485-47dc-829e-43be7f4db57b"
   },
   "source": [
    "- The most common ways to finetune language models are instruction-finetuning and classification finetuning\n",
    "- Instruction-finetuning, depicted below, is the topic of the next notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c29ef42-46d9-43d4-8bb4-94974e1665e4",
   "metadata": {
    "id": "6c29ef42-46d9-43d4-8bb4-94974e1665e4"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/instructions.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f60321-95b8-46a9-97bf-1d07fda2c3dd",
   "metadata": {
    "id": "a7f60321-95b8-46a9-97bf-1d07fda2c3dd"
   },
   "source": [
    "- Classification finetuning, the topic of this chapter, is a procedure you may already be familiar with if you have a background in machine learning -- it's similar to training a convolutional network to classify handwritten digits, for example\n",
    "- In classification finetuning, we have a specific number of class labels (for example, \"spam\" and \"not spam\") that the model can output\n",
    "- A classification finetuned model can only predict classes it has seen during training (for example, \"spam\" or \"not spam\"), whereas an instruction-finetuned model can usually perform many tasks\n",
    "- We can think of a classification-finetuned model as a very specialized model; in practice, it is much easier to create a specialized model than a generalist model that performs well on many different tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b37a0c4-0bb1-4061-b1fe-eaa4416d52c3",
   "metadata": {
    "id": "0b37a0c4-0bb1-4061-b1fe-eaa4416d52c3"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/spam-non-spam.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf",
   "metadata": {
    "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf"
   },
   "source": [
    "## STEP 1 :  Preparing the dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d",
   "metadata": {
    "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d"
   },
   "source": [
    "- This section prepares the dataset we use for classification finetuning\n",
    "- We use a dataset consisting of spam and non-spam text messages to finetune the LLM to classify them\n",
    "- First, we download and unzip the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
    "outputId": "6b84ff67-37c8-439b-9479-9bf9d3805d76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the dataset...\n",
      "Extracting the dataset...\n",
      "File downloaded and saved as sms_spam_collection/SMSSpamCollection.tsv\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# URL of the dataset zip file\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"  # Local path to save the downloaded zip file\n",
    "extracted_path = \"sms_spam_collection\"  # Directory to extract the contents of the zip file\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"  # Final path of the TSV file\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    # Check if the data file already exists\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Downloading the zip file\n",
    "    print(\"Downloading the dataset...\")\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the downloaded file\n",
    "    print(\"Extracting the dataset...\")\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Renaming the original file to add the .tsv extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "# Call the function to download and extract the dataset\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1",
   "metadata": {
    "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1"
   },
   "source": [
    "- The dataset is saved as a tab-separated text file, which we can load into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
    "outputId": "c6df2e98-6f28-45bf-9bf5-74241510ab27"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-12dda0e2-c389-4a01-a9b4-0d81b27b9d60\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will √º b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows √ó 2 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12dda0e2-c389-4a01-a9b4-0d81b27b9d60')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-12dda0e2-c389-4a01-a9b4-0d81b27b9d60 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-12dda0e2-c389-4a01-a9b4-0d81b27b9d60');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-ca01a085-a58b-40eb-ac37-74f39938eebc\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ca01a085-a58b-40eb-ac37-74f39938eebc')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-ca01a085-a58b-40eb-ac37-74f39938eebc button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_bf9db6c7-6dd1-4633-97d8-be8941fdea14\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_bf9db6c7-6dd1-4633-97d8-be8941fdea14 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will √º b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109",
   "metadata": {
    "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109"
   },
   "source": [
    "- When we check the class distribution, we see that the data contains \"ham\" (i.e., \"not spam\") much more frequently than \"spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
    "outputId": "3f6ae6fd-223e-49d6-b4fc-353e59ebae25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773f054-0bdc-4aad-bbf6-397621bf63db",
   "metadata": {
    "id": "f773f054-0bdc-4aad-bbf6-397621bf63db"
   },
   "source": [
    "- For simplicity, and because we prefer a small dataset for educational purposes anyway (it will make it possible to finetune the LLM faster), we subsample (undersample) the dataset so that it contains 747 instances from each class\n",
    "- (Next to undersampling, there are several other ways to deal with class balances, you may refer to sklearn exllent docs on this subject(https://imbalanced-learn.org/stable/user_guide.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7be4a0a2-9704-4a96-b38f-240339818688",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7be4a0a2-9704-4a96-b38f-240339818688",
    "outputId": "40272fc4-9100-4218-d471-202123652493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    # Count the instances of \"spam\"\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "\n",
    "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "\n",
    "    # Combine the sampled ham subset with all spam instances\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "# Assuming df is your DataFrame containing the dataset\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "\n",
    "# Print the value counts to verify the balance\n",
    "print(balanced_df[\"Label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6",
   "metadata": {
    "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6"
   },
   "source": [
    "- Next, we change the string class labels \"ham\" and \"spam\" into integer class labels 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd",
    "outputId": "32ef7fb0-3fe3-4f2e-9850-ce00184d510f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows √ó 1 columns</p>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "4307    0\n",
       "4138    0\n",
       "4831    0\n",
       "4461    0\n",
       "5440    0\n",
       "       ..\n",
       "5537    1\n",
       "5540    1\n",
       "5547    1\n",
       "5566    1\n",
       "5567    1\n",
       "Name: Label, Length: 1494, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "balanced_df[\"Label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f",
   "metadata": {
    "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f"
   },
   "source": [
    "- Let's now define a function that randomly divides the dataset into training, validation, and test subsets using the good old sklerarn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "uQl0Psdmx15D",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQl0Psdmx15D",
    "outputId": "f0203f6a-812e-4dff-ac8a-1a2485b02aaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1045, 2)\n",
      "Validation set shape: (149, 2)\n",
      "Test set shape: (300, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'balanced_df' is your DataFrame and the labels are in the 'Label' column\n",
    "# Make a copy to avoid modifying the original DataFrame\n",
    "data = balanced_df.copy()\n",
    "\n",
    "# First, split the data into training (70%) and temporary (30%)\n",
    "train_data, temp_data = train_test_split(data, test_size=0.3, random_state=123, stratify=data[\"Label\"])\n",
    "\n",
    "# Then, split the temporary data into validation (10%) and test (20%)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.6667, random_state=123, stratify=temp_data[\"Label\"])\n",
    "\n",
    "# Save the splits to CSV files with both inputs and targets\n",
    "train_data.to_csv(\"train_data.csv\", index=False)\n",
    "val_data.to_csv(\"val_data.csv\", index=False)\n",
    "test_data.to_csv(\"test_data.csv\", index=False)\n",
    "\n",
    "# Display the shape of the splits\n",
    "print(f\"Training set shape: {train_data.shape}\")  # Includes input and target\n",
    "print(f\"Validation set shape: {val_data.shape}\")  # Includes input and target\n",
    "print(f\"Test set shape: {test_data.shape}\")        # Includes input and target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d7a0c5-1d5f-458a-b685-3f49520b0094",
   "metadata": {
    "id": "a8d7a0c5-1d5f-458a-b685-3f49520b0094"
   },
   "source": [
    "## Creating data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c",
   "metadata": {
    "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c"
   },
   "source": [
    "- Note that the text messages have different lengths; if we want to combine multiple training examples in a batch, we have to either\n",
    "  1. truncate all messages to the length of the shortest message in the dataset or batch\n",
    "  2. pad all messages to the length of the longest message in the dataset or batch\n",
    "\n",
    "- We choose option 2 and pad all messages to the longest message in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
    "outputId": "513cb99f-8707-4c87-cf96-6b807d9d4c7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f582ff-68bf-450e-bd87-5fb61afe431c",
   "metadata": {
    "id": "04f582ff-68bf-450e-bd87-5fb61afe431c"
   },
   "source": [
    "- The `SpamDataset` class below identifies the longest sequence in the training dataset and adds the padding token to the others to match that sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7791b52-af18-4ac4-afa9-b921068e383e",
   "metadata": {
    "id": "d7791b52-af18-4ac4-afa9-b921068e383e"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        \"\"\"\n",
    "        Initializes the SpamDataset.\n",
    "\n",
    "        Args:\n",
    "            csv_file (str): Path to the CSV file containing the dataset.\n",
    "            tokenizer: The tokenizer used to encode the text data.\n",
    "            max_length (int, optional): Maximum length of the encoded sequences.\n",
    "                                         If None, the longest sequence will be used.\n",
    "            pad_token_id (int, optional): Token ID used for padding (default is 50256).\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)  # Load data from the CSV file\n",
    "\n",
    "        # Pre-tokenize texts using the provided tokenizer\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        # Determine the maximum length for encoding\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()  # Set max length to the longest encoded length\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pad sequences to ensure they all have the same length\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Retrieves the encoded text and its corresponding label.\n",
    "\n",
    "        Args:\n",
    "            index (int): Index of the item to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing:\n",
    "                - torch.Tensor: The encoded text as a tensor.\n",
    "                - torch.Tensor: The corresponding label as a tensor.\n",
    "        \"\"\"\n",
    "        encoded = self.encoded_texts[index]  # Get the encoded text at the specified index\n",
    "        label = self.data.iloc[index][\"Label\"]  # Get the corresponding label\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),  # Convert encoded text to a tensor\n",
    "            torch.tensor(label, dtype=torch.long)     # Convert label to a tensor\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples in the dataset.\"\"\"\n",
    "        return len(self.data)  # Return the length of the dataset\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        \"\"\"\n",
    "        Calculates the length of the longest encoded text.\n",
    "\n",
    "        Returns:\n",
    "            int: The length of the longest encoded text.\n",
    "        \"\"\"\n",
    "        max_length = 0  # Initialize max_length to 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)  # Get the length of the current encoded text\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length  # Update max_length if the current length is greater\n",
    "        return max_length  # Return the longest length found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "uzj85f8ou82h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzj85f8ou82h",
    "outputId": "a806ac6b-c39b-4f61-82a2-4a5329481f2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train_data.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bdd932-97eb-4b88-9cf9-d766ea4c3a60",
   "metadata": {
    "id": "15bdd932-97eb-4b88-9cf9-d766ea4c3a60"
   },
   "source": [
    "- We also pad the validation and test set to the longest training sequence\n",
    "- Note that validation and test set samples that are longer than the longest training example are being truncated via `encoded_text[:self.max_length]` in the `SpamDataset` code\n",
    "- This behavior is entirely optional, and it would also work well if we set `max_length=None` in both the validation and test set cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e",
   "metadata": {
    "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e"
   },
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"val_data.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test_data.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
   "metadata": {
    "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57",
   "metadata": {
    "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57"
   },
   "source": [
    "- As a verification step, we iterate through the data loaders and ensure that the batches contain 8 training examples each, where each training example consists of 120 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
    "outputId": "e459a4a8-55e1-457f-c905-ed1636d2ef02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1",
   "metadata": {
    "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1"
   },
   "source": [
    "- Lastly, let's print the total number of batches in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "IZfw-TYD2zTj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZfw-TYD2zTj",
    "outputId": "64704702-f6f4-4ae4-9985-728b93781af3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c",
   "metadata": {
    "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c"
   },
   "source": [
    "## Step 2 :  Initializing a model with pretrained weights\n",
    "\n",
    "lets set up the model configration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2992d779-f9fb-4812-a117-553eb790a5a9",
   "metadata": {
    "id": "2992d779-f9fb-4812-a117-553eb790a5a9"
   },
   "outputs": [],
   "source": [
    "# Choose the model to use\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "\n",
    "# Base configuration settings for the model\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Size of the vocabulary used by the model\n",
    "    \"context_length\": 1024,  # Maximum context length the model can handle\n",
    "    \"drop_rate\": 0.0,        # Dropout rate for regularization\n",
    "    \"qkv_bias\": True         # Whether to use bias terms in query, key, and value projections\n",
    "}\n",
    "\n",
    "# Dictionary containing configurations for different GPT-2 model sizes\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},      # Config for small model\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},    # Config for medium model\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},     # Config for large model\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},       # Config for extra-large model\n",
    "}\n",
    "\n",
    "# Update the BASE_CONFIG with parameters specific to the chosen model\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "# Assert to check that the maximum length of the training dataset does not exceed the model's context length\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7925b5",
   "metadata": {},
   "source": [
    "### Loading the GPT Model\n",
    "\n",
    "In this section, we will accomplish the following:\n",
    "\n",
    "1. **Load the GPT model** that we built from scratch in the previous notebooks.\n",
    "2. **Utilize utility functions** to download and integrate the model weights.\n",
    "\n",
    "**Important Notes:**\n",
    "\n",
    "- All relevant code is located in the `UTILS` folder within the same directory.\n",
    "- The functions `download_and_load_gpt2` and `load_weights_into_gpt` are derived from Sebastian Raschka, the author of *Building LLMs from Scratch*. You can find the source link in the code comments.\n",
    "- Alternatively, you can load the weights using Hugging Face's library; however, I prefer this method for its intuitive approach and deeper understanding of the underlying processes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022a649a-44f5-466c-8a8e-326c063384f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "022a649a-44f5-466c-8a8e-326c063384f5",
    "outputId": "eb6bc5f5-5d5d-49ce-bff6-b86f8287a237"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from UTILS.load_weights import download_and_load_gpt2 , load_weights_into_gpt\n",
    "from UTILS.model import GPTModel\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e056c-abe0-415f-b34d-df686204259e",
   "metadata": {
    "id": "ab8e056c-abe0-415f-b34d-df686204259e"
   },
   "source": [
    "- To ensure that the model was loaded correctly, let's double-check that it generates coherent text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce39ed0-2c77-410d-8392-dd15d4b22016",
   "metadata": {
    "id": "1ce39ed0-2c77-410d-8392-dd15d4b22016"
   },
   "source": [
    "- As we can see, the model is not very good at following instructions\n",
    "- This is expected, since it has only been pretrained and not instruction-finetuned (instruction finetuning will be covered in the next chapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522",
   "metadata": {
    "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522"
   },
   "source": [
    "## Step 3 : Adding a classification head (and freezing the model)\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"images/classification_finetune.png\" alt=\"My Image\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217bac05-78df-4412-bd80-612f8061c01d",
   "metadata": {
    "id": "217bac05-78df-4412-bd80-612f8061c01d"
   },
   "source": [
    "- In this section, we are modifying the pretrained LLM to make it ready for classification finetuning\n",
    "- Let's take a look at the model architecture first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b23aff91-6bd0-48da-88f6-353657e6c981",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b23aff91-6bd0-48da-88f6-353657e6c981",
    "outputId": "dd50cbe2-e10d-4336-8c3f-a9a28c3b623c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f640a76-dd00-4769-9bc8-1aed0cec330d",
   "metadata": {
    "id": "3f640a76-dd00-4769-9bc8-1aed0cec330d"
   },
   "source": [
    "In this section, we will focus on the model we built in Notebook 3. Our objectives are as follows:\n",
    "\n",
    "1. **Freeze the Model Graph**: We will freeze the model's parameters to prevent retraining the entire architecture, which helps retain the knowledge learned during initial training.\n",
    "\n",
    "2. **Replace the Final Layer**: We will replace the final layer (`out_head`) with a new classification layer tailored for our specific task.\n",
    "\n",
    "3. **Unfreeze Specific Layers**: To enhance model performance, we will strategically unfreeze additional layers closer to the output. Specifically, we will unfreeze the last layer of the transformer block as well as the final layer normalization (`final_norm`). This approach is expected to yield better results by allowing the model to adapt more effectively to our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fkMWFl-0etea",
   "metadata": {
    "id": "fkMWFl-0etea"
   },
   "outputs": [],
   "source": [
    "# 1- Freeze the Model Graph\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 2- Replace the Final Layer\n",
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)\n",
    "\n",
    "# 3- Unfreeze last transformer block  and final normalization Layers\n",
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aa4aef-e1e9-491b-9adf-5aa973e59b8c",
   "metadata": {
    "id": "32aa4aef-e1e9-491b-9adf-5aa973e59b8c"
   },
   "source": [
    "## Step 4 :  Calculating the classification loss and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb20d3a-cbba-4ab1-8584-d94e16589505",
   "metadata": {
    "id": "dcb20d3a-cbba-4ab1-8584-d94e16589505"
   },
   "source": [
    "- We can apply this concept to calculate the so-called classification accuracy, which computes the percentage of correct predictions in a given dataset\n",
    "- To calculate the classification accuracy, we can apply the preceding `argmax`-based prediction code to all examples in a dataset and calculate the fraction of correct predictions as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d8f6cb",
   "metadata": {},
   "source": [
    "Let‚Äôs create a mock-up tensor to explain how the accuracy calculation works in the `calc_accuracy_loader` function. We will simulate some input and target data, and then step through the function while calculating the accuracy based on this mock data.\n",
    "\n",
    "### Mock Data\n",
    "\n",
    "We‚Äôll create:\n",
    "- **Input Tensor**: Simulated model predictions (logits).\n",
    "- **Target Tensor**: True labels for the data.\n",
    "\n",
    "\n",
    "**Predicted Labels**:\n",
    "   We apply the `argmax` operation to the logits to determine the predicted class for each sample.`\n",
    "\n",
    "   The `predicted_labels` will be:\n",
    "   - Sample 1: 0 (correct)\n",
    "   - Sample 2: 1 (correct)\n",
    "   - Sample 3: 2 (correct)\n",
    "   - Sample 4: 0 (incorrect, true label is 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebc70806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "# Mock input tensor representing model predictions (logits)\n",
    "# Shape: (batch_size, num_classes)\n",
    "# Here, we assume a batch size of 4 and 3 classes.\n",
    "input_logits = torch.tensor([\n",
    "    [2.0, 1.0, 0.1],  # Sample 1: class 0 is predicted\n",
    "    [0.5, 2.0, 0.5],  # Sample 2: class 1 is predicted\n",
    "    [0.2, 0.1, 3.0],  # Sample 3: class 2 is predicted\n",
    "    [0.0, 0.0, 0.0]   # Sample 4: no prediction (edge case)\n",
    "])\n",
    "\n",
    "# Mock target tensor representing true labels\n",
    "# Shape: (batch_size,)\n",
    "true_labels = torch.tensor([0, 1, 2, 1])  # True classes for the 4 samples\n",
    "\n",
    "# Convert logits to predicted labels using argmax\n",
    "predicted_labels = torch.argmax(input_logits, dim=-1)\n",
    "\n",
    "predicted_labels = torch.argmax(input_logits, dim=-1)\n",
    "print(predicted_labels)  # Output: tensor([0, 1, 2, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400be2d2",
   "metadata": {},
   "source": [
    "**Counting Correct Predictions**:\n",
    "   Now we compare the predicted labels with the true labels to count how many predictions are correct.\n",
    "\n",
    " \n",
    "   The comparison will yield:\n",
    "   - Sample 1: Correct (predicted 0, true 0)\n",
    "   - Sample 2: Correct (predicted 1, true 1)\n",
    "   - Sample 3: Correct (predicted 2, true 2)\n",
    "   - Sample 4: Incorrect (predicted 0, true 1)\n",
    "\n",
    "   So, there are 3 correct predictions out of 4 samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ced16e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    " \n",
    "correct_predictions = (predicted_labels == true_labels).sum().item()\n",
    "print(correct_predictions)  # Output: 3\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a06ae0",
   "metadata": {},
   "source": [
    "\n",
    "4. **Calculating Accuracy**:\n",
    "   Finally, we calculate accuracy by dividing the number of correct predictions by the total number of samples.\n",
    "\n",
    "\n",
    "   The accuracy calculation will be:\n",
    "   \\[\n",
    "   \\text{Accuracy} = \\frac{\\text{Correct Predictions}}{\\text{Total Samples}} = \\frac{3}{4} = 0.75\n",
    "   \\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d57df4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_examples = true_labels.shape[0]  # Total number of samples\n",
    "accuracy = correct_predictions / num_examples\n",
    "print(f\"Accuracy: {accuracy:.2f}\")  # Output: Accuracy: 0.75\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a8077b",
   "metadata": {},
   "source": [
    "Now lets implement in a consice function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3ecf9572-aed0-4a21-9c3b-7f9f2aec5f23",
   "metadata": {
    "id": "3ecf9572-aed0-4a21-9c3b-7f9f2aec5f23"
   },
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7165fe46-a284-410b-957f-7524877d1a1a",
   "metadata": {
    "id": "7165fe46-a284-410b-957f-7524877d1a1a"
   },
   "source": [
    "- Let's apply the function to calculate the classification accuracies for the different datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "390e5255-8427-488c-adef-e1c10ab4fb26",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "390e5255-8427-488c-adef-e1c10ab4fb26",
    "outputId": "ce887ccf-74fc-4c1e-b30f-38608e7e4e21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 62.50%\n",
      "Test accuracy: 46.25%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# As of this writing, in PyTorch 2.4, the results obtained via CPU and MPS were identical.\n",
    "# However, in earlier versions of PyTorch, you may observe different results when using MPS.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "#print(f\"Running on {device} device.\")\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30345e2a-afed-4d22-9486-f4010f90a871",
   "metadata": {
    "id": "30345e2a-afed-4d22-9486-f4010f90a871"
   },
   "source": [
    "- As we can see, the prediction accuracies are not very good, since we haven't finetuned the model, yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4a9d15-8fc7-48a2-8734-d92a2f265328",
   "metadata": {
    "id": "4f4a9d15-8fc7-48a2-8734-d92a2f265328"
   },
   "source": [
    "- Before we can start finetuning (/training), we first have to define the loss function we want to optimize during training\n",
    "- The goal is to maximize the spam classification accuracy of the model; however, classification accuracy is not a differentiable function\n",
    "- Hence, instead, we minimize the cross-entropy loss as a proxy for maximizing the classification accuracy \n",
    "\n",
    "- The `calc_loss_batch` function is the same here as notebook 5.1, except that we are only interested in optimizing the last token `model(input_batch)[:, -1, :]` instead of all tokens `model(input_batch)` , which contain the information about the class label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4",
   "metadata": {
    "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4"
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a013aab9-f854-4866-ad55-5b8350adb50a",
   "metadata": {
    "id": "a013aab9-f854-4866-ad55-5b8350adb50a"
   },
   "source": [
    "The `calc_loss_loader` is exactly the same as notebook 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7b83e10-5720-45e7-ac5e-369417ca846b",
   "metadata": {
    "id": "b7b83e10-5720-45e7-ac5e-369417ca846b"
   },
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56826ecd-6e74-40e6-b772-d3541e585067",
   "metadata": {
    "id": "56826ecd-6e74-40e6-b772-d3541e585067"
   },
   "source": [
    "- Using the `calc_closs_loader`, we compute the initial training, validation, and test set losses before we start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
    "outputId": "6b8fee13-f501-4aee-85f3-ade2695f2c8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.442\n",
      "Validation loss: 2.186\n",
      "Test loss: 2.822\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b980b-e583-4f62-84a0-4edafaf99d5d",
   "metadata": {
    "id": "e04b980b-e583-4f62-84a0-4edafaf99d5d"
   },
   "source": [
    "- In the next section, we train the model to improve the loss values and consequently the classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456ae0fd-6261-42b4-ab6a-d24289953083",
   "metadata": {
    "id": "456ae0fd-6261-42b4-ab6a-d24289953083"
   },
   "source": [
    "## Step 5 : Finetuning the model on supervised data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9b099b-0829-4f72-8a2b-4363e3497026",
   "metadata": {
    "id": "6a9b099b-0829-4f72-8a2b-4363e3497026"
   },
   "source": [
    "- In this section, we define and use the training function to improve the classification accuracy of the model\n",
    "- The `train_classifier_simple` function below is practically the same as the `train_model_simple` function we used for pretraining the model in chapter 5\n",
    "- The only two differences are that we now\n",
    "  1. track the number of training examples seen (`examples_seen`) instead of the number of tokens seen\n",
    "  2. calculate the accuracy after each epoch instead of printing a sample text after each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b6222-1dc2-4530-9d01-b6b04fe3de12",
   "metadata": {
    "id": "979b6222-1dc2-4530-9d01-b6b04fe3de12"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/training-loop.webp?1\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "Csbr60to50FL",
   "metadata": {
    "id": "Csbr60to50FL"
   },
   "outputs": [],
   "source": [
    "# Overall the same as `train_model_simple` in chapter 5\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9624cb30-3e3a-45be-b006-c00475b58ae8",
   "metadata": {
    "id": "9624cb30-3e3a-45be-b006-c00475b58ae8"
   },
   "source": [
    "- The `evaluate_model` function used in the `train_classifier_simple` is the same as the one we used in notebook 5.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcc7bc04-6aa6-4516-a147-460e2f466eab",
   "metadata": {
    "id": "bcc7bc04-6aa6-4516-a147-460e2f466eab"
   },
   "outputs": [],
   "source": [
    "# Same as chapter 5\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e807bfe9-364d-46b2-9e25-3b000c3ef6f9",
   "metadata": {
    "id": "e807bfe9-364d-46b2-9e25-3b000c3ef6f9"
   },
   "source": [
    "- The training takes about 5 minutes on a M3 MacBook Air laptop computer and less than half a minute on a V100 or A100 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "X7kU3aAj7vTJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7kU3aAj7vTJ",
    "outputId": "5d1e4949-986c-4bb8-cfc6-1cf685225f0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 3.004, Val loss 2.024\n",
      "Ep 1 (Step 000050): Train loss 0.644, Val loss 0.650\n",
      "Ep 1 (Step 000100): Train loss 0.543, Val loss 0.607\n",
      "Training accuracy: 65.00% | Validation accuracy: 70.00%\n",
      "Ep 2 (Step 000150): Train loss 0.594, Val loss 0.574\n",
      "Ep 2 (Step 000200): Train loss 0.348, Val loss 0.554\n",
      "Ep 2 (Step 000250): Train loss 0.364, Val loss 0.621\n",
      "Training accuracy: 87.50% | Validation accuracy: 75.00%\n",
      "Ep 3 (Step 000300): Train loss 0.302, Val loss 0.535\n",
      "Ep 3 (Step 000350): Train loss 0.443, Val loss 0.509\n",
      "Training accuracy: 82.50% | Validation accuracy: 72.50%\n",
      "Ep 4 (Step 000400): Train loss 0.489, Val loss 0.531\n",
      "Ep 4 (Step 000450): Train loss 0.275, Val loss 0.390\n",
      "Ep 4 (Step 000500): Train loss 0.186, Val loss 0.538\n",
      "Training accuracy: 95.00% | Validation accuracy: 85.00%\n",
      "Ep 5 (Step 000550): Train loss 0.283, Val loss 0.298\n",
      "Ep 5 (Step 000600): Train loss 0.195, Val loss 0.250\n",
      "Training accuracy: 95.00% | Validation accuracy: 92.50%\n",
      "Training completed in 2.38 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f099769",
   "metadata": {},
   "source": [
    "## Implementing a FineTuner Class for a Modular Training Loop\n",
    "\n",
    "To streamline the training process, we will create a `FineTuner` class that encompasses all essential elements into a cohesive workflow.\n",
    "\n",
    "### Important\n",
    "\n",
    "If you're familiar with our previous notebook, where we implemented an optimized training loop to train GPT-2 from scratch, you‚Äôll recall that we utilized several advanced techniques, including:\n",
    "\n",
    "- Mixed precision\n",
    "- Gradient clipping and accumulation\n",
    "- Multi-GPU training\n",
    "- `torch.compile()`\n",
    "\n",
    "### Why Simplify?\n",
    "\n",
    "You might wonder why we're implementing these methods here, especially given their complexity. The answer is straightforward: \n",
    "\n",
    "I did experiment with these optimizations, but I encountered diminishing returns. The task at hand is relatively simple, and the intricate training loop I devised resulted in longer training times and numerous errors‚Äîissues that are not conducive to effective learning.\n",
    "\n",
    "In contrast, I achieved **97% accuracy in just minutes of training** on a single GPU using Google Colab with a simpler approach. \n",
    "\n",
    "### Lesson Learned\n",
    "\n",
    "The moral of the story is that **more complexity is not always better**. It's crucial to assess the specific problem at hand and implement an appropriate level of complexity to effectively solve it. By striking the right balance, we can achieve efficient results without unnecessary complications.\n",
    "\n",
    "Now lets continue  :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "J4apK9XzFYlM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J4apK9XzFYlM",
    "outputId": "4df954c6-fb0f-49dc-a2d6-3aae1ba334c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Average Training Loss: 0.1285, Training Accuracy: 95.69%, Time: 24.69s\n",
      "Validation Loss: 0.1416, Validation Accuracy: 0.9463\n",
      "Epoch [2/5], Average Training Loss: 0.1080, Training Accuracy: 96.46%, Time: 32.68s\n",
      "Validation Loss: 0.1389, Validation Accuracy: 0.9530\n",
      "Epoch [3/5], Average Training Loss: 0.0935, Training Accuracy: 96.56%, Time: 17.49s\n",
      "Validation Loss: 0.1271, Validation Accuracy: 0.9463\n",
      "Epoch [4/5], Average Training Loss: 0.0791, Training Accuracy: 97.22%, Time: 17.61s\n",
      "Validation Loss: 0.1321, Validation Accuracy: 0.9530\n",
      "Epoch [5/5], Average Training Loss: 0.0707, Training Accuracy: 97.61%, Time: 17.48s\n",
      "Validation Loss: 0.1255, Validation Accuracy: 0.9530\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Optimize the model for performance\n",
    "model = torch.compile(model)\n",
    "\n",
    "class FineTuner:\n",
    "    def __init__(self, model, train_loader, val_loader, num_epochs=5, device=None):\n",
    "        \"\"\"\n",
    "        Initialize the FineTuner with model and data loaders.\n",
    "\n",
    "        Args:\n",
    "            model: The neural network model to be fine-tuned.\n",
    "            train_loader: DataLoader for the training dataset.\n",
    "            val_loader: DataLoader for the validation dataset.\n",
    "            num_epochs: Number of epochs for training (default is 5).\n",
    "            device: Device to run the model on (CPU or GPU).\n",
    "        \"\"\"\n",
    "        self.model = model  # Store the model\n",
    "        self.train_loader = train_loader  # Store the training DataLoader\n",
    "        self.val_loader = val_loader  # Store the validation DataLoader\n",
    "        self.num_epochs = num_epochs  # Store the number of epochs\n",
    "        self.device = device if device else torch.device('cpu')  # Set the device to GPU or CPU\n",
    "\n",
    "        # Initialize the optimizer with a smaller learning rate\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
    "        self.model.to(self.device)  # Move the model to the specified device\n",
    "\n",
    "    def train_model(self):\n",
    "        \"\"\"\n",
    "        Train the model for the specified number of epochs.\n",
    "        \"\"\"\n",
    "        self.model.train()  # Set the model to training mode\n",
    "        for epoch in range(self.num_epochs):\n",
    "            start_time = time.time()  # Start timing the epoch\n",
    "            total_loss = 0  # Initialize total loss for the epoch\n",
    "            correct_predictions = 0  # To track correct predictions during the epoch\n",
    "\n",
    "            for step, batch in enumerate(self.train_loader):\n",
    "                inputs, labels = batch  # Unpack the input data and labels\n",
    "                inputs = inputs.to(self.device)  # Move inputs to the specified device\n",
    "                labels = labels.to(self.device)  # Move labels to the specified device\n",
    "\n",
    "                self.optimizer.zero_grad()  # Reset gradients before backward pass\n",
    "\n",
    "                outputs = self.model(inputs)  # Forward pass through the model\n",
    "                logits = outputs[:, -1, :]  # Get the logits for the last output token\n",
    "                loss = torch.nn.functional.cross_entropy(logits, labels)  # Calculate the loss\n",
    "\n",
    "                loss.backward()  # Backward pass to calculate gradients\n",
    "                self.optimizer.step()  # Update the model weights\n",
    "\n",
    "                total_loss += loss.item()  # Accumulate loss\n",
    "\n",
    "                # Track correct predictions\n",
    "                _, preds = torch.max(logits, dim=1)  # Get predicted labels\n",
    "                correct_predictions += torch.sum(preds == labels).item()  # Count correct predictions\n",
    "\n",
    "            average_loss = total_loss / len(self.train_loader)  # Calculate average loss for the epoch\n",
    "            epoch_time = time.time() - start_time  # Calculate the time taken for the epoch\n",
    "            train_accuracy = correct_predictions / len(self.train_loader.dataset)  # Calculate training accuracy\n",
    "\n",
    "            # Print training statistics for the epoch\n",
    "            print(f\"Epoch [{epoch + 1}/{self.num_epochs}], \"\n",
    "                  f\"Average Training Loss: {average_loss:.4f}, \"\n",
    "                  f\"Training Accuracy: {train_accuracy * 100:.2f}%, \"\n",
    "                  f\"Time: {epoch_time:.2f}s\")\n",
    "\n",
    "            # Evaluate on the validation set after each epoch\n",
    "            val_loss, val_accuracy = self.evaluate_model()\n",
    "            print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        \"\"\"\n",
    "        Evaluate the model on the validation set.\n",
    "\n",
    "        Returns:\n",
    "            average_eval_loss: Average loss on the validation set.\n",
    "            accuracy: Accuracy on the validation set.\n",
    "        \"\"\"\n",
    "        self.model.eval()  # Set the model to evaluation mode\n",
    "        total_eval_loss = 0  # Initialize total validation loss\n",
    "        correct_predictions = 0  # Initialize count of correct predictions\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "            for batch in self.val_loader:\n",
    "                inputs, labels = batch  # Unpack the input data and labels\n",
    "                inputs = inputs.to(self.device)  # Move inputs to the specified device\n",
    "                labels = labels.to(self.device)  # Move labels to the specified device\n",
    "\n",
    "                outputs = self.model(inputs)  # Forward pass through the model\n",
    "                logits = outputs[:, -1, :]  # Get the logits for the last output token\n",
    "                loss = torch.nn.functional.cross_entropy(logits, labels)  # Calculate the loss\n",
    "                total_eval_loss += loss.item()  # Accumulate validation loss\n",
    "\n",
    "                _, preds = torch.max(logits, dim=1)  # Get predicted labels\n",
    "                correct_predictions += torch.sum(preds == labels).item()  # Count correct predictions\n",
    "\n",
    "        # Calculate average loss and accuracy for the validation set\n",
    "        average_eval_loss = total_eval_loss / len(self.val_loader)\n",
    "        accuracy = correct_predictions / len(self.val_loader.dataset)\n",
    "\n",
    "        return average_eval_loss, accuracy  # Return average loss and accuracy\n",
    "\n",
    "    def fine_tune_model(self):\n",
    "        \"\"\"\n",
    "        Initiate the training of the model.\n",
    "        \"\"\"\n",
    "        self.train_model()  # Start the training process\n",
    "\n",
    "# Usage example\n",
    "# Assuming you have already initialized train_loader and val_loader\n",
    "# model = ...  # Load your pre-trained model from Hugging Face\n",
    "fine_tuner = FineTuner(model, train_loader, val_loader, num_epochs=5)\n",
    "fine_tuner.fine_tune_model()  # Fine-tune the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1261bf90-3ce7-4591-895a-044a05538f30",
   "metadata": {
    "id": "1261bf90-3ce7-4591-895a-044a05538f30"
   },
   "source": [
    "We use matplotlib to plot the loss function for the training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cURgnDqdCeka",
   "metadata": {
    "id": "cURgnDqdCeka"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "OIqRt466DiGk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "OIqRt466DiGk",
    "outputId": "927ab34b-348c-4887-e9e1-75f64ca25077"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd28174-1836-44ba-b6c0-7e0be774fadc",
   "metadata": {
    "id": "dbd28174-1836-44ba-b6c0-7e0be774fadc"
   },
   "source": [
    "- Above, based on the downward slope, we see that the model learns well\n",
    "- Furthermore, the fact that the training and validation loss are very close indicates that the model does not tend to overfit the training data\n",
    "- Similarly, we can plot the accuracy below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "yz8BIsaF0TUo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "yz8BIsaF0TUo",
    "outputId": "25ca0496-a794-4471-b474-4baf7b2a4a50"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aba699-21bc-42de-a69c-99f370bb0363",
   "metadata": {
    "id": "90aba699-21bc-42de-a69c-99f370bb0363"
   },
   "source": [
    "- Based on the accuracy plot above, we can see that the model achieves a relatively high training and validation accuracy after epochs 4 and 5\n",
    "- However, we have to keep in mind that we specified `eval_iter=5` in the training function earlier, which means that we only estimated the training and validation set performances\n",
    "- We can compute the training, validation, and test set performances over the complete dataset as follows below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "UHWaJFrjY0zW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHWaJFrjY0zW",
    "outputId": "6e9f5242-4d9f-4ca3-ed78-92d476aec722"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 98.17%\n",
      "Validation accuracy: 95.30%\n",
      "Test accuracy: 97.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6882649f-dc7b-401f-84d2-024ff79c74a1",
   "metadata": {
    "id": "6882649f-dc7b-401f-84d2-024ff79c74a1"
   },
   "source": [
    "- We can see that the training and validation set performances are practically identical\n",
    "- However, based on the slightly lower test set performance, we can see that the model overfits the training data to a very small degree, as well as the validation data that has been used for tweaking some of the hyperparameters, such as the learning rate\n",
    "- This is normal, however, and this gap could potentially be further reduced by increasing the model's dropout rate (`drop_rate`) or the `weight_decay` in the optimizer setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d9ad7-3ec1-450e-8c9f-4fc46d3d5bb0",
   "metadata": {
    "id": "a74d9ad7-3ec1-450e-8c9f-4fc46d3d5bb0"
   },
   "source": [
    "## Step 6 : Using the LLM as a spam classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5408e6-83e4-4e5a-8503-c2fba6073f31",
   "metadata": {
    "id": "fd5408e6-83e4-4e5a-8503-c2fba6073f31"
   },
   "source": [
    "- Finally, let's use the finetuned GPT model in action\n",
    "- The `classify_review` function below implements the data preprocessing steps similar to the `SpamDataset` we implemented earlier\n",
    "- Then, the function returns the predicted integer class label from the model and returns the corresponding class name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aHdn6xvL-IW5",
   "metadata": {
    "id": "aHdn6xvL-IW5"
   },
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
    "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
    "\n",
    "    # Truncate sequences if they too long\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    # Pad sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Return the classified result\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29682d8-a899-4d9b-b973-f8d5ec68172c",
   "metadata": {
    "id": "f29682d8-a899-4d9b-b973-f8d5ec68172c"
   },
   "source": [
    "- Let's try it out on a few examples below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "apU_pf51AWSV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apU_pf51AWSV",
    "outputId": "fbe041f2-494d-4e6a-ce03-66338ba18ec4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1g5VTOo_Ajs5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1g5VTOo_Ajs5",
    "outputId": "7e30d3ad-8b75-4f78-8800-39e111b050f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf736e39-0d47-40c1-8d18-1f716cf7a81e",
   "metadata": {
    "id": "bf736e39-0d47-40c1-8d18-1f716cf7a81e"
   },
   "source": [
    "- Finally, let's save the model in case we want to reuse the model later without having to train it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "mYnX-gI1CfQY",
   "metadata": {
    "id": "mYnX-gI1CfQY"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78cf7c-6b80-4f71-a50e-3ccc73839af6",
   "metadata": {
    "id": "ba78cf7c-6b80-4f71-a50e-3ccc73839af6"
   },
   "source": [
    "- Then, in a new session, we could load the model as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cc4e68a5-d492-493b-87ef-45c475f353f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cc4e68a5-d492-493b-87ef-45c475f353f5",
    "outputId": "655b12c5-2c89-4d00-87a9-af1f37cb87dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\", map_location=device, weights_only=True)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafdc910-d616-47ab-aa85-f90c6e7ed80e",
   "metadata": {
    "id": "dafdc910-d616-47ab-aa85-f90c6e7ed80e"
   },
   "source": [
    "## Summary and Takeaways\n",
    "\n",
    "In this notebook, we explored various aspects of fine-tuning a pre-trained GPT model using PyTorch. The process involved several key components and methodologies designed to optimize model performance and training efficiency. \n",
    "\n",
    "### Key Components Covered\n",
    "\n",
    "1. **Data Preparation**: We began by effectively splitting our dataset into training, validation, and test sets using different methods. This ensured that our model could be trained and evaluated properly without overfitting.\n",
    "\n",
    "2. **Model Definition**: The architecture of our GPT model was defined, taking into account the specific requirements for our classification task. \n",
    "\n",
    "3. **Training Loop**: We implemented a straightforward yet efficient training loop, which included:\n",
    "   - Calculation of loss using cross-entropy.\n",
    "   - Tracking of correct predictions for accuracy evaluation.\n",
    "   - Optimization through backpropagation with the AdamW optimizer.\n",
    "\n",
    "4. **Validation Process**: After each epoch, we evaluated the model's performance on a validation set to gauge its generalization capability.\n",
    "\n",
    "5. **Modular Approach with FineTuner Class**: We encapsulated the training logic within a `FineTuner` class to promote code reusability and organization. This class includes methods for training, evaluation, and fine-tuning the model.\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Simplicity Over Complexity**: A simple training loop can yield excellent results without the overhead of advanced techniques. Our approach achieved a notable accuracy of 97% in a short training time on a single GPU.\n",
    "\n",
    "2. **Regular Evaluation is Crucial**: Evaluating the model on a validation set after each training epoch provides vital feedback on its performance, helping to avoid overfitting and ensuring better generalization.\n",
    "\n",
    "3. **Modular Design for Flexibility**: The use of a modular class like `FineTuner` allows for easy updates and modifications in future projects, making it adaptable to varying needs.\n",
    "\n",
    "4. **Focus on Fundamentals**: Understanding the core principles of training and evaluating neural networks can lead to better results, even when more complex methods are available.\n",
    "\n",
    "5. **Resource Management**: Efficient use of computational resources (like using the correct device) is essential for maximizing performance and minimizing training time.\n",
    "\n",
    "By synthesizing these insights and methodologies, practitioners can effectively fine-tune models and achieve high performance while maintaining clarity and efficiency in their training processes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273b0e35",
   "metadata": {},
   "source": [
    "## üéâ Congratulations, You Made It! üéâ\n",
    "\n",
    "You've just conquered this notebook, and what an adventure it has been! You've taken your first steps into the exciting world of building a large language model (LLM) from scratch. Sure, we tackled a classic machine learning problem‚Äîtext classification‚Äîbut don‚Äôt underestimate it! This journey is like laying the first brick of a grand castle that will be your foundation for more ambitious projects ahead. \n",
    "\n",
    "Your hard work here is paving the way for some truly awesome applications, and you're building a rock-solid intuition that will serve you well as we dive deeper into the realm of natural language processing.\n",
    "\n",
    "### üöÄ What‚Äôs Coming Up Next?\n",
    "\n",
    "But wait, the fun isn‚Äôt over! In our next notebook, we‚Äôll be taking things up a notch with **instruction following**. Get ready to watch your model learn how to follow user instructions like a pro‚Äîit‚Äôs going to be a game changer!\n",
    "\n",
    "And that's not all! We'll also explore some nifty techniques for optimized fine-tuning, including **LoRA (Low-Rank Adaptation)** and **QLoRA (Quantized Low-Rank Adaptation)**. Trust me, these tools are like secret weapons that will make your models even more efficient and powerful.\n",
    "\n",
    "Thank you for bringing your energy and enthusiasm to this notebook! Buckle up; the next leg of our journey promises to be just as thrilling! Let‚Äôs keep the momentum going! üöÄüí™\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
