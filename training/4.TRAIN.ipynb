{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import tiktoken\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "\n",
    "GPT_CONFIG_124 = {\n",
    "        \"vocab_size\": 50257,     # Vocabulary size\n",
    "        \"context_length\": 265,  # Context length\n",
    "        \"emb_dim\": 768,          # Embedding dimension\n",
    "        \"n_heads\": 12,           # Number of attention heads\n",
    "        \"n_layers\": 12,          # Number of layers\n",
    "        \"drop_rate\": 0.1,        # Dropout rate\n",
    "        \"qkv_bias\": False        # Query-Key-Value bias\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file collects all the relevant code that we covered thus far\n",
    "# throughout Chapters 2-4.\n",
    "# This file can be run as a standalone script.\n",
    "\n",
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#####################################\n",
    "# Chapter 2\n",
    "#####################################\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
    "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "#####################################\n",
    "# Chapter 3\n",
    "#####################################\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads  # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x)  # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)  # optional projection\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "\n",
    "#####################################\n",
    "# Chapter 4\n",
    "#####################################\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)   # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed-forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (B, T) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "\n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_token, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest logits value\n",
    "        idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken \n",
    "\n",
    "def text_to_tokens_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    return torch.tensor(encoded).unsqueeze(0)\n",
    "\n",
    "def token_ids_to_text(ids, tokenizer):\n",
    "    return tokenizer.decode(ids.squeeze(0).tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_context = \"Every effort move you\"\n",
    "tok = tiktoken.encoding_for_model(\"gpt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort move you chemist penalzipulence portal\" cacaker picint\n"
     ]
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124)\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model = model,\n",
    "    idx = text_to_tokens_ids(start_context, tok),\n",
    "    max_new_tokens = 10,\n",
    "    context_size = GPT_CONFIG_124[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20479\n",
      "5145\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "total_chars = len(text)\n",
    "total_tokens = len(tok.encode(text))\n",
    "print(total_chars) \n",
    "print(total_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text))\n",
    "train_data = text[:split_idx]\n",
    "val_data = text[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "\n",
    "def GPTDataloaderv1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = GPTDataloaderv1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124[\"context_length\"],\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = GPTDataloaderv1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124[\"context_length\"],\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4240\n",
      "Validation tokens: 530\n",
      "All tokens: 4770\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 265]) torch.Size([2, 265])\n",
      "torch.Size([2, 265]) torch.Size([2, 265])\n",
      "torch.Size([2, 265]) torch.Size([2, 265])\n",
      "torch.Size([2, 265]) torch.Size([2, 265])\n",
      "torch.Size([2, 265]) torch.Size([2, 265])\n",
      "torch.Size([2, 265]) torch.Size([2, 265])\n",
      "torch.Size([2, 265]) torch.Size([2, 265])\n",
      "torch.Size([2, 265]) torch.Size([2, 265])\n",
      "Val loader:\n",
      "torch.Size([2, 265]) torch.Size([2, 265])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x,y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    \n",
    "print(\"Val loader:\")\n",
    "for x,y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 7.783483505249023\n",
      "Validation loss: 8.06966781616211\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_tokens_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.703, Val loss 10.000\n",
      "Ep 1 (Step 000005): Train loss 7.931, Val loss 8.363\n",
      "Every effort moves you.                                                 \n",
      "Ep 2 (Step 000010): Train loss 6.774, Val loss 7.170\n",
      "Ep 2 (Step 000015): Train loss 5.934, Val loss 6.710\n",
      "Every effort moves you.                                                 \n",
      "Ep 3 (Step 000020): Train loss 5.792, Val loss 6.577\n",
      "Every effort moves you to the was.    \". Gis. Gisburn, and, and.               \" a.  \", and, and.   \n",
      "Ep 4 (Step 000025): Train loss 5.509, Val loss 6.445\n",
      "Ep 4 (Step 000030): Train loss 4.684, Val loss 6.291\n",
      "Every effort moves you of the was a, and I had been to have he was in the--and the, and I had a, and I had a, and I had been the, and in the the, and he was a, and I had been the\n",
      "Ep 5 (Step 000035): Train loss 4.345, Val loss 6.348\n",
      "Every effort moves you of the, with a.  \"I have a little in him--and I felt.        \"I't--and he said, with a little. \"I was his pictures--and the the\n",
      "Ep 6 (Step 000040): Train loss 3.567, Val loss 6.331\n",
      "Ep 6 (Step 000045): Train loss 3.237, Val loss 6.229\n",
      "Every effort moves you of the picture. The, as if he was dead--I that he had been the picture--I looked about him, and he had been the picture of the end with her.   \"Oh, and he was not that he was\n",
      "Ep 7 (Step 000050): Train loss 2.718, Val loss 6.214\n",
      "Ep 7 (Step 000055): Train loss 2.148, Val loss 6.227\n",
      "Every effort moves you of the fact with a.  \"I have him, and I had a little:--I looked up at the; but I felt him. \"I turned, and he was his painting. I had a little: \"strong he\n",
      "Ep 8 (Step 000060): Train loss 1.801, Val loss 6.364\n",
      "Every effort moves you know with the stream, I had been he was, and I!                      \"I was his wife a picture was not till after a a he\n",
      "Ep 9 (Step 000065): Train loss 1.258, Val loss 6.282\n",
      "Ep 9 (Step 000070): Train loss 1.048, Val loss 6.362\n",
      "Every effort moves you of the hour. The younger artist was said to have formed himself at my friend's feet, and I wondered if a tinge of jealousy underlay the latter's mysterious abdication. But no--for it was not till after that event that\n",
      "Ep 10 (Step 000075): Train loss 0.932, Val loss 6.403\n",
      "Every effort moves you know the hour. The younger artist was said to have formed himself at my friend's feet, and I wondered if a tinge of jealousy underlay the latter's mysterious abdication. But no--for it was not till after that event that\n",
      "Training completed in 19.11 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Note:\n",
    "# Uncomment the following code to calculate the execution time\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tok\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to show the execution time\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, label=\"validation loss\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc = \"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
