### **MyLLM101: Building LLMs from Scratch**

---

### **Core Ideas of the Project**
The goal of **MyLLM101** is to build and understand Large Language Models (LLMs) from the ground up using **PyTorch**. The focus is on building everything yourself — from data preprocessing to model training, optimization, and fine-tuning. Once this foundational knowledge is built, you will move on to using advanced tools like Hugging Face, LangChain, and others for real-world applications.

1. **Data Preprocessing**
   - Develop custom data preprocessing pipelines including tokenization, padding, batching, and dataset management.
   - Learn the ins and outs of dataset handling for NLP tasks (training, validation, test splits).

2. **Models (GPT, LLAMA, BERT)**
   - Build foundational models such as GPT, LLAMA, and BERT from scratch. Implement the transformer architecture, attention mechanisms, and embedding layers.
   - Gain deep insights into how each model works, with a focus on their specific differences and use cases.

3. **Training**
   - Set up a simple training pipeline using PyTorch. Train the models from scratch using a custom dataset.
   - Learn essential concepts like optimization, loss functions, and backpropagation in the context of LLMs.
   - Enhance the training pipeline by integrating advanced techniques like gradient checkpointing, mixed-precision training, and distributed training strategies.
   - Implement optimization methods to speed up training and reduce memory consumption.

4. **UI**
   - Implement a simple UI with **Gradio** to showcase the trained models and perform basic inference.
   - Learn how to interact with LLMs through a user-friendly interface for text generation and other NLP tasks.


6. **Fine-Tuning**
   - Fine-tune models on your custom dataset without relying on Hugging Face or other libraries. This includes adjusting hyperparameters and modifying architectures for specific tasks.
   - Learn how to handle overfitting, underfitting, and model selection during fine-tuning.
   - Explore more efficient fine-tuning methods such as LoRA (Low-Rank Adaptation) and learn how to use pre-trained models while applying custom optimizations to improve performance.
   - Utilize techniques for more efficient parameter updates and better model generalization.

8. **Inference Optimization (Quantization / Pruning)**
   - Implement techniques like **quantization** and **pruning** to reduce model size and speed up inference without sacrificing performance.
   - Learn the impact of these techniques on model performance, accuracy, and inference speed.

9. **Retrieval-Augmented Generation (RAG) from Scratch**
   - Build a custom RAG pipeline to combine information retrieval and text generation.
   - Focus on creating your own retrieval system and integrating it with LLMs to generate more accurate, contextually relevant responses.
   - Do not use external libraries like LangChain or LlamaIndex for this phase to gain full control and understanding of the process.

10. **Pipeline Development**
   - Develop a modular training, fine-tuning, and inference pipeline that can be reused as a library.
   - Create a "tiny Hugging Face" library for training, fine-tuning, and inference, providing flexibility and control over every component.

BONUS. **Tokenization**
   - Build a **custom BPE (Byte Pair Encoding)** tokenizer from scratch, understanding how to handle subword tokenization and vocabulary building.
---

### **MyLLM Directory Structure**

```plaintext
MyLLM101/
│
├── Data/
│   └── Custom data pipeline (tokenization, preprocessing scripts, dataset generators)
│
├── Models/
│   └── GPT, LLAMA, BERT models built from scratch (transformer architecture, attention, and more)
│
├── FineTuning/
│   └── Fine-tuning pipeline (custom model loading, transfer learning, hyperparameter tuning)
│
├── UI/
│   └── Gradio apps for inference, showcasing model results, and experimenting with various tasks
│
├── RAG/
│   └── Custom Retrieval-Augmented Generation pipeline (document retrieval, query generation)
│
├── Optimization/
│   └── Training and inference optimization strategies (distributed training, pruning, quantization)
│
├── Pipeline/
│   └── A reusable library for training, inference, fine-tuning, and RAG integration
│
├── Notebooks/
│   └── Detailed documentation, tutorials, and experiment logs (exploratory analysis and testing)
│
├── README.md
└── requirements.txt
```

---

### **Project Development Phases**

1. **Phase 1: Core Concepts & Model Building**
   -  Focus on understanding the transformer architecture, implementing tokenization, preprocessing, and building basic models like GPT, LLAMA, and BERT from scratch. Train them using custom data and simple pipelines.
   
2. **Phase 2: Training & Optimization Techniques**
   - Dive into training optimization techniques like distributed training, mixed-precision, gradient checkpointing, and fine-tuning models with custom datasets.

3. **Phase 3: Advanced Optimization & Inference**
   -  Explore advanced inference optimization techniques such as pruning and quantization to make models more efficient for production. Fine-tune models with new optimization methods.

4. **Phase 4: RAG Pipeline & Real-World Applications**
   - Build the RAG pipeline from scratch and integrate it with the LLMs. Once you have the pipeline working, explore deploying the models using tools like **FastAPI** or **Docker** for real-world applications.

---

### **Learning Approach: "Build It Before You Use It"**

The essence of **MyLLM101** is to **build everything from scratch** before relying on any external libraries or pre-trained models. The purpose of this project is to help you **deeply understand** how each component of an LLM works — from data preprocessing and model building to training, fine-tuning, and optimization. This foundation will give you the freedom to work with any external tool (like Hugging Face, LangChain, etc.) in a more efficient, informed, and customized manner.

By the end of this project, you will have:
- A strong understanding of transformer-based models and NLP tasks.
- Mastery over fine-tuning, training optimization, and inference improvements.
- A customized LLM library and an RAG pipeline built from scratch.
- The ability to integrate your models into real-world applications without depending entirely on pre-built solutions.

---

### **Key Takeaway**
**MyLLM101** is all about **mastering LLMs from scratch**. The knowledge and skills gained through this process will be your foundation for creating powerful, optimized LLM-based applications that you can confidently deploy and scale using advanced tools later.

### **"Build It Before You Use It."**

---

### **Notebooks Section**

1. **Data**: Explore data preprocessing, tokenization, and dataset handling.
2. **Attention**: Dive deep into understanding the self-attention mechanism.
3. **GPT**: Study the implementation and working of GPT models.
4. **Training**: Learn the basics of model training, optimization, and loss functions.
5. **Inference 1**: Perform basic inference with trained models.
6. **Training Pro**: Advanced training techniques like gradient checkpointing and distributed training.
7. **Fine-Tuning 1**: Fine-tune models on custom datasets for specific tasks.
8. **Optimized Fine-Tuning**: Efficient fine-tuning techniques, like LoRA.
9. **From GPT-2 to LLAMA2**: Transition from GPT-2 to LLAMA2 models.
10. **LLAMA 3 from Scratch**: Implement and train LLAMA3 from scratch.
11. **Tokenization**: Build and understand tokenization (e.g., BPE).
12. **Inference 2 (Optimization)**: Explore advanced optimization techniques for inference, like pruning and quantization.
13. **RAG**: Build and explore a custom Retrieval-Augmented Generation pipeline.

---
